= Trusted Software Supply Chain with RHDH for Production

== What is 'end product'?

So far in this course we have looked at the individual components of the composite solution. This module will explain how they all work together, and more importantly why this is a crucial product set for end customers.

In order to understand this we need to look at the concept of 'End Product'. This is the deliverables from one part of an organisation to another; the point of currency. With developers this used to be massively varied, some organisations wanted developers to deliver code, some binaries, some composite packages etc. In the new world of DevSecOps and the advent of the inner and outer loops we now have a defined point of delivery for developers - code in a git repo.

With the concept of inner loop (where the developer works) doing code generation, functional testing and delivery via Git, and the outer loop (where Ops and Platform Engineers work) handling the build, functional/non-functional test and deployment, the need for security to be applied and compared much earlier on in the software lifecycle became critical.

In the old days of waterfall security was basically the last thing to be checked (if at all). This meant that it was at the point of functional/non-functional testing that security checks were applied; if they failed it was back to the beginning, with the developers having to produce code which went through the entire lifecycle again. 

The concept of shift-left brings security much earlier in the software generation cycle. RHDH and TSSC provide secure tooling to allow developers to see potential security issues as they type their code, and TSSC detecting and recording potential security issues as part of the standard build approach. 

How this works from the product perspective is as follows; RHDH provides the configurable Developer portal, including direct linkage to in-browser editors, via OpenShift DevSpaces. RHADS provides extensions for these in-browser editors to highlight potential CVE exploit points, so a developer can directly see the issues as they develop. 

TSSC provides some pre-built Tekton pipelines that perform a source-to-image build, depending on the language framework, and apply a set of security protocols to it as part of the build process. This locks the generation of end-product, in this case the Application Image, into a 'security-fail' approach, where if any of the checks fail the build fails. 

In addition, TSSC generates SBOMs (Software Bill of Material) which record exactly what components were used to create the digital artifacts. These SBOMs are also now part of the 'end-product', and are generated and maintained as part of the TSSC pipeline. 

Finally, to make it all seamless, the templates used to create the scaffolding for the developer generates the code repository, webhooks so *any* update to the code repository causes the TSSC pipeline to start, and generates all the deployable components for the Application on OpenShift using ArgoCD.

This last point is very important; rather than interact directly with the Cluster from the scaffolding perspective, all components/objects are applied via GitOps. This allows the template, executed in RHDH, to scaffold not only the developer environment (the Git repositories and in-browser editors) but the TSSC Pipelines *and* the end deployment components. 

No part of the process from the point at which the developer submits the code ('end-product') to final deployment post build and security check is not automated.

== Why do we need RHDH and TSSC?

As it stands TSSC provides the pre-defined Tekton pipelines for performing all of the checks and build components to take a piece of source and generate a useable Image along with all the receipts (SBOMs) in the case of a successful build, or pinpoint log information as to why the build failed/was stopped by security. However this is just a set of Tekton pipeline definitions; you need to be able to run them (i.e. OpenShift). In addition there are a huge amount of parameters to provide - these Pipelines were built as part of the original RHTAP (Trusted Application Pipeline) product which was designed to be hosted, so they can be troublesome to configure. 

With the advent of TPA (Trusted Profile Analyser, the SBOM generator and maintainer) and TAS (Trusted Artifact Signer, cryptographic signing and verification), which, combined, provide the receipts for the Image and a secure Image itself, the combination of TSSC, TAS and TPA gives the whole secure process, but again you need to parameterise it appropriately.

With RHDH you have the capability of writing templates which walk the user through a sequential set of steps in order to scaffold an environment. What we have done with RHADS is to build an opinionated approach, through templates in RHDH, for using TSSC and the other components. This approach makes it much easier for a Platform Engineer to setup the process, and much easier (with way less cognitive load) for a Developer to use. In fact a Developer will be largely insulated from the process, which makes a Developer's life easier. 

== Positioning the technical components

When talking to customers from a technical perspective, RHADS is an easy pitch - developers want a simplified way to be able to write the software without getting bogged down in the minutiae around the processes of getting started and building/delivering the end product, which is where Backstage/RHDH is positioned. Ops want secured software that has been tested for potential exploits before it gets to the functional/non-functional end testing phases. 

Put simply, TSSC/TAS/TPA give you automated build and security scanning, point of truth (SBOM generation and maintenance) and the stamp of security approval (cryptographic signing).

Most customers are doing these things already but the diversity of solutions means it is a headache to maintain these build factories/pipelines. RHADS, through the developer facing components of RHDH and the Ops facing components of end-product generation with TSSC, TAS and TPA, solves a lot of this complexity and provides clear and defined interaction points; the developers work with templates (which can be extended if the organisation needs additional steps for scaffolding), the Ops/Platform Engineers work by maintaining the template and pre-generated Tekton pipelines from TSSC. 

For the majority of organisations, the out-of-the-box functionality provided by the templates and the standard TSSC pipelines will suffice to provide a solid secure development/build lifecycle. 

== Understanding the process

=== Scaffolding with templates and the TSSC pipelines

The key component in all of this approach is the RHDH template. This is a configurable object that defines a set of actions to be executed sequentially; if all actions complete successfully, the template is deemed to have completed. If any actions fail, the template stops at that point.

It is worth understanding what is meant by an action in a template; as you have seen in previous modules, the framework of Backstage and therefore RHDH provides massive extensibility using the concepts of 'plugins'. These provide two forms of extension for the framework, visual components that can be rendered as part of the composite portal provided to the end consumer, and executable endpoints that are satisfied outside of the framework. These endpoints are the powerful parts - they provide verbs that can be consumed as a step in a template.

Let's look at an example part of one of the templates here to show how they are used - this is the template will we execute as part of the hands-on lab:

```yaml
apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  name: quarkus-stssc-template
  title: Securing a Quarkus Service Software Supply Chain (Tekton)
  description: Create a Quarkus Service built with Red Hat Trusted Application Pipeline on Tekton
  tags:
    - recommended
    - java
    - quarkus
    - maven
```

The template starts with metadata that is used within the framework for display and selection. The tags are actually rendered on the selection tile in the provisioned portal. As with all objects, the definition is split into the metadata, shown above, and the specification of the object, in this case the template definition. 

```yaml
spec:
  owner: tssc
  type: service
```

The specification starts with some core definition fields, in this case the owner object and the type of object produced by the template. Now we have an extract of the parameters section of the specification:

```yaml
  parameters:
    - title: Provide Information for Application
      required:
        - name
        - javaPackageName
      properties:
        name:
          title: Name
          type: string
          description: Unique name of the component
          default: my-quarkus-tkn
          ui:field: EntityNamePicker
          maxLength: 23
        groupId:
          title: Group Id
          type: string
          default: redhat.rhdh
          description: Maven Group Id
        artifactId:
          title: Artifact Id
          type: string
          default: my-quarkus-tkn
          description: Maven Artifact Id
        javaPackageName:
          title: Java Package Name
          default: org.redhat.rhdh
          type: string
          description: Name for the java package. eg (com.redhat.blah)
        description:
          title: Description
          type: string
          description: Help others understand what this website is for.
          default: A cool quarkus app
    - title: Provide Image Registry Information
      required:
        - imageHost
        - imageOrganization
      properties:
        imageHost:
          title: Image Registry
          type: string
          default: Quay
          enum:
            - Quay
        imageOrganization:
          title: Organization
          type: string
          description: Name of the Quay Organization
          default: tssc
```
When you, as a user of the portal generated by RHDH, instantiate a template, the framework parses all of the parameters required in the specification; these are rendered as wizards, with each `title:` group being rendered as a separate form. This is an extract, but note the first 'form', 'Provide Information for Application'. This has the defined parameters name, groupID etc - each parameter can be defined to be optional or mandatory, and a default value can be provided. As we will see in the steps defined next in the template, these parameters are tokenised by the parser and then embedded into the action calls in the steps. Here's an example couple of steps:

```yaml
steps:
    - id: fetch-provision-data
      name: Fetch Provision Data
      action: catalog:fetch
      input:
        entityRef: component:default/provisioning-data

    - id: template
      name: Fetch Skeleton + Template
      action: fetch:template
      input:
        url: ./skeleton
        values:
          name: ${{ parameters.name }}
          namespace: tssc-app
          description: ${{ parameters.description }}
          groupId: ${{ parameters.groupId }}
          artifactId: ${{ parameters.artifactId }}
          javaPackageName: ${{ parameters.javaPackageName }}
          owner: user:default/${{ user.entity.metadata.name }}
          cluster: ${{ steps["fetch-provision-data"].output.entity.metadata.labels["ocp-apps-domain"] }}
          gitlabHost: gitlab-gitlab.${{ steps["fetch-provision-data"].output.entity.metadata.labels["ocp-apps-domain"] }}
          quayHost: quay-${{ steps["fetch-provision-data"].output.entity.metadata.labels["guid"] }}.${{ steps["fetch-provision-data"].output.entity.metadata.labels["ocp-apps-domain"] }}
          destination: ${{ parameters.repoOwner }}/${{ parameters.name }}
          quayDestination: ${{ parameters.imageOrganization}}/${{ parameters.name }}
          port: 8080
          verifyCommits: ${{ parameters.repoVerifyCommits }}
```
Firstly note that every step has an `action:` field. This refers to either a built in action (the `fetch:template` and `catalog:fetch` are pre-built actions in the core framework) or an action provided by a plugin; in the hands-on lab we will see that the next step is actually `publish:gitlab`, which is an action to push the file system created to GitLab. This functionality is provided in the appropriate plugin added to the core framework.

At the end of the template are a set of 'outputs'. These are rendered components on the portal that link to entities physically created by the template:

```yaml
output:
    links:
      - title: Source Repository
        url: ${{ steps['publish-gitlab-source'].output.remoteUrl }}
      - title: GitOps Repository
        url: ${{ steps['publish-gitlab-gitops'].output.remoteUrl }}
      - title: Open Component in catalog
        icon: catalog
        entityRef: ${{ steps['register-source'].output.entityRef }}
      - title: Open GitOps Resource in catalog
        icon: catalog
        entityRef: ${{ steps['register-gitops'].output.entityRef }}
```
Note that like the parameters, the framework will generate tokens based on the output of the steps - everything bound by double curly-brackets is a token replacement - example here is `steps['publish-gitlab-source'].output.remoteUrl`, which is the URL that is created for the repo that is scaffolded by one of the steps.

It is also worth being aware of the way that the templates actually work behind the scenes; when a template is instantiated it has a working directory. In the example above the catalog:fetch and fetch:template actually copy files into this temporary area. Then the action (not shown) for publishing to gitlab pushes this area as the files into the repo. 

In actuality the `fetch:template` gets *all* the files needed, including the YAML definitions for both the TSSC pipeline and the final deployed application (in various staging projects). RHDH and the template have no knowledge directly of the ArgoCD, Tekton or OpenShift objects, the template is working as a scaffolder. There are actions later in the template to `argocd:create-resources` which use a subdirectory of the scaffolded git repo as the location of the components to instantiate. Like the steps in the template, these are parametrised with content from the template, which allows for the unique creation of the pipelines and ArgoCD applications for this instance. 

It sounds complex but when you realise that the template is just marshaling, scaffolding and deploying files, and the actions of the plugins are doing the work in terms of creating and kicking off the pipelines for build and securing, it becomes simpler to visualise.

The TSSC pipelines themselves are created by the ArgoCD components and initially contain the opinionated, secure pipelines provided out of the box by RHADS. It must be noted that customers can (and should, if needed) add and alter these pipelines if they have additional security checks and processes to execute as part of the build. In the hands-on lab we will dive into the definition to show where and how this can be changed, but, as said earlier, the majority of end customer security needs will be met by the default security actions provided in the base TSSC pipelines.

=== Tying the loop; hooking code updates to pipeline

So far we have looked at the templating mechanism and how it scaffolds the application; in addition it used ArgoCD to setup a number of effective release gates (_dev_, _pre-prod_, _production_ etc) which can be configured by changing the ArgoCD application definitions and overlays. This, combined with the real-time code updates we discussed earlier (using the DevSpaces plugins) gives the framework for development and staging, but we are missing one vital component.

Tekton (the Pipeline functionality) was designed to allow for the creation of `PipelineRun`s (the actual execution of a Pipeline as opposed to the definition) through a web endpoint, using EventListeners. What we have done with RHADS is provide some out-of-the-box interactions with Git repositories providers (i.e. GitHub, GitLab) which setup webhooks based around the code repositories that are scaffolded as part of the template.

In English, the instantiation of the template not only creates the code repositories to be used and the environments on the OpenShift cluster for the application deployment, it also adds triggers into the code repository to automatically repeat the build pipeline on commits - effectively when the end user commits code to the repository, the pipeline triggers in the appropriate created environments and repeats the entire secure build process.

This guarantees that any code changes to the scaffolded git repos are automatically rebuilt, checked for security issues and receipted and signed using the TPA and TAS components. Again, this automation makes both the developer and the ops persona's lives much easier.


